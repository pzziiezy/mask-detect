# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import os

print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Mask Detection with VGG16!")
print(f"TensorFlow version: {tf.__version__}")

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
IMG_SIZE = 224  # VGG16 ‡πÉ‡∏ä‡πâ 224x224
BATCH_SIZE = 32
EPOCHS = 30  # ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏û‡∏£‡∏≤‡∏∞ VGG16 ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤

# ‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
train_dir = 'data/train'
validation_dir = 'data/Validation'
test_dir = 'data/test'

print("\nüìÅ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")

# Data Augmentation ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 20
    width_shift_range=0.3,  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.2
    height_shift_range=0.3,
    horizontal_flip=True,
    zoom_range=0.3,  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å 0.2
    brightness_range=[0.5, 1.5],  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á
    shear_range=0.2,  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ö‡∏¥‡∏î
    fill_mode='nearest'
)

validation_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='binary'
)

validation_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    shuffle=False
)

print(f"\n‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ Training: {train_generator.samples}")
print(f"‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ Validation: {validation_generator.samples}")
print(f"‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏π‡∏õ Test: {test_generator.samples}")
print(f"üìä Classes: {train_generator.class_indices}")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• VGG16
print("\nüèóÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• VGG16...")

# ‡πÇ‡∏´‡∏•‡∏î VGG16 pre-trained (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° top layer)
base_model = VGG16(
    weights='imagenet',
    include_top=False,
    input_shape=(IMG_SIZE, IMG_SIZE, 3)
)

# Freeze base model layers (‡πÑ‡∏°‡πà train ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ)
base_model.trainable = False

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
model = keras.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')
])

# Compile ‡πÇ‡∏°‡πÄ‡∏î‡∏•
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

print("\nüìã ‡∏™‡∏£‡∏∏‡∏õ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:")
model.summary()

# Callbacks
early_stopping = keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

reduce_lr = keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    min_lr=1e-7
)

# Train ‡πÇ‡∏°‡πÄ‡∏î‡∏• (Phase 1: Frozen base)
print(f"\nüéØ Phase 1: Training with frozen VGG16 base...")
print(f"Training for {EPOCHS} epochs...\n")

history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=validation_generator,
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

# Fine-tuning (Phase 2: Unfreeze some layers)
print("\nüî• Phase 2: Fine-tuning (unfreezing last 4 layers)...")

# Unfreeze ‡∏ä‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á VGG16
base_model.trainable = True
for layer in base_model.layers[:-4]:
    layer.trainable = False

# Compile ‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ learning rate ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-5),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Train ‡∏ï‡πà‡∏≠
history_fine = model.fit(
    train_generator,
    epochs=10,  # Train ‡∏ï‡πà‡∏≠‡∏≠‡∏µ‡∏Å 10 epochs
    validation_data=validation_generator,
    callbacks=[early_stopping, reduce_lr],
    verbose=1
)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
model_path = 'models/mask_detector_vgg16.h5'
model.save(model_path)
print(f"\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà: {model_path}")

# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ Test set
print("\nüìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ Test set...")
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"\n‚úÖ Test Accuracy: {test_accuracy*100:.2f}%")
print(f"‚úÖ Test Loss: {test_loss:.4f}")

# ‡∏£‡∏ß‡∏° history ‡∏à‡∏≤‡∏Å 2 phases
all_history = {
    'accuracy': history.history['accuracy'] + history_fine.history['accuracy'],
    'val_accuracy': history.history['val_accuracy'] + history_fine.history['val_accuracy'],
    'loss': history.history['loss'] + history_fine.history['loss'],
    'val_loss': history.history['val_loss'] + history_fine.history['val_loss']
}

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
print("\nüìà ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå...")

plt.figure(figsize=(14, 5))

# ‡∏Å‡∏£‡∏≤‡∏ü Accuracy
plt.subplot(1, 2, 1)
plt.plot(all_history['accuracy'], label='Training Accuracy')
plt.plot(all_history['val_accuracy'], label='Validation Accuracy')
plt.axvline(x=len(history.history['accuracy']), color='r', linestyle='--', label='Fine-tuning starts')
plt.title('VGG16 Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# ‡∏Å‡∏£‡∏≤‡∏ü Loss
plt.subplot(1, 2, 2)
plt.plot(all_history['loss'], label='Training Loss')
plt.plot(all_history['val_loss'], label='Validation Loss')
plt.axvline(x=len(history.history['loss']), color='r', linestyle='--', label='Fine-tuning starts')
plt.title('VGG16 Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig('models/training_history_vgg16.png')
print("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏µ‡πà: models/training_history_vgg16.png")

print("\nüéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡πÇ‡∏°‡πÄ‡∏î‡∏• VGG16 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡πâ‡∏ß")
print(f"üìä Final Test Accuracy: {test_accuracy*100:.2f}%")